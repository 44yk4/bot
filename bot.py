import logging
from telegram import Update, ReplyKeyboardMarkup, ReplyKeyboardRemove
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    filters,
    ConversationHandler,
    ContextTypes
)
import requests

# ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸
TOKEN = "YOUR_TELEGRAM_BOT_TOKEN"  # Ð—Ð°Ð¼ÐµÐ½Ð¸Ñ‚Ðµ Ð½Ð° Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ‚Ð¾ÐºÐµÐ½
API_URL = "http://localhost:5000/predict"

# Ð¡Ð¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°
BRAND, MODEL, RAM, STORAGE, SCREEN_SIZE = range(5)

# ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(name)

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await update.message.reply_text(
        "ðŸ’» *Laptop Price Predictor Bot*\n\n"
        "Ð¯ Ð¼Ð¾Ð³Ñƒ Ð¾Ñ†ÐµÐ½Ð¸Ñ‚ÑŒ ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ Ð²Ð°ÑˆÐµÐ³Ð¾ Ð½Ð¾ÑƒÑ‚Ð±ÑƒÐºÐ°!\n"
        "ÐÐ°Ð¶Ð¼Ð¸Ñ‚Ðµ /predict Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ð°Ñ‡Ð°Ñ‚ÑŒ Ð¾Ñ†ÐµÐ½ÐºÑƒ.",
        parse_mode='Markdown'
    )

async def predict(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    brands = [['Apple', 'Dell'], ['HP', 'Lenovo'], ['Asus', 'Acer']]
    await update.message.reply_text(
        "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð±Ñ€ÐµÐ½Ð´ Ð½Ð¾ÑƒÑ‚Ð±ÑƒÐºÐ°:",
        reply_markup=ReplyKeyboardMarkup(brands, one_time_keyboard=True)
    )
    return BRAND

async def get_brand(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    context.user_data['brand'] = update.message.text
    await update.message.reply_text(
        "Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð½Ð¾ÑƒÑ‚Ð±ÑƒÐºÐ°:",
        reply_markup=ReplyKeyboardRemove()
    )
    return MODEL

async def get_model(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    context.user_data['model'] = update.message.text
    await update.message.reply_text("Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð¾Ð±ÑŠÐµÐ¼ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¸Ð²Ð½Ð¾Ð¹ Ð¿Ð°Ð¼ÑÑ‚Ð¸ (Ð² Ð“Ð‘):")
    return RAM

async def get_ram(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    try:
        ram = int(update.message.text)
        if ram < 2 or ram > 64:
            raise ValueError
        context.user_data['ram'] = ram
        await update.message.reply_text("Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð¾Ð±ÑŠÐµÐ¼ Ð½Ð°ÐºÐ¾Ð¿Ð¸Ñ‚ÐµÐ»Ñ (Ð² Ð“Ð‘):")
        return STORAGE
    except ValueError:
        await update.message.reply_text("ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð²Ð²ÐµÐ´Ð¸Ñ‚Ðµ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¹ Ð¾Ð±ÑŠÐµÐ¼ RAM (Ð¾Ñ‚ 2 Ð´Ð¾ 64 Ð“Ð‘):")
        return RAM

async def get_storage(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    try:
        storage = int(update.message.text)
        if storage < 128 or storage > 4096:
            raise ValueError
        context.user_data['storage'] = storage
        await update.message.reply_text("Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ñ€Ð°Ð·Ð¼ÐµÑ€ ÑÐºÑ€Ð°Ð½Ð° (Ð² Ð´ÑŽÐ¹Ð¼Ð°Ñ…):")
        return SCREEN_SIZE
    except ValueError:
        await update.message.reply_text("ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð²Ð²ÐµÐ´Ð¸Ñ‚Ðµ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¹ Ð¾Ð±ÑŠÐµÐ¼ Ð½Ð°ÐºÐ¾Ð¿Ð¸Ñ‚ÐµÐ»Ñ (128-4096 Ð“Ð‘):")
        return STORAGE

chayka, [6/10/25 6:15â€¯AM]
async def get_screen_size(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    try:
        screen_size = float(update.message.text.replace(',', '.'))
        if screen_size < 10.0 or screen_size > 17.0:
            raise ValueError
        context.user_data['screen_size'] = screen_size
        
        try:
            response = requests.post(API_URL, json=context.user_data)
            if response.status_code == 200:
                result = response.json()
                laptop = context.user_data
                message = (
                    f"ðŸ’» *{laptop['brand']} {laptop['model']}*\n\n"
                    f"â–ªï¸ ÐžÐ¿ÐµÑ€Ð°Ñ‚Ð¸Ð²Ð½Ð°Ñ Ð¿Ð°Ð¼ÑÑ‚ÑŒ: {laptop['ram']} Ð“Ð‘\n"
                    f"â–ªï¸ ÐÐ°ÐºÐ¾Ð¿Ð¸Ñ‚ÐµÐ»ÑŒ: {laptop['storage']} Ð“Ð‘\n"
                    f"â–ªï¸ Ð”Ð¸Ð°Ð³Ð¾Ð½Ð°Ð»ÑŒ ÑÐºÑ€Ð°Ð½Ð°: {laptop['screen_size']}\"\n\n"
                    f"ðŸ’µ *ÐžÑ†ÐµÐ½ÐºÐ° ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚Ð¸:* ${result['price']:,}"
                )
                await update.message.reply_text(
                    message,
                    parse_mode='Markdown',
                    reply_markup=ReplyKeyboardMarkup([['/predict']], resize_keyboard=True)
                )
            else:
                await update.message.reply_text("âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ñ€Ð°ÑÑ‡ÐµÑ‚Ðµ Ñ†ÐµÐ½Ñ‹")
        except Exception as e:
            await update.message.reply_text(f"ðŸš¨ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ: {str(e)}")
        
        return ConversationHandler.END
    except ValueError:
        await update.message.reply_text("ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð²Ð²ÐµÐ´Ð¸Ñ‚Ðµ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¹ Ñ€Ð°Ð·Ð¼ÐµÑ€ ÑÐºÑ€Ð°Ð½Ð° (10.0-17.0 Ð´ÑŽÐ¹Ð¼Ð¾Ð²):")
        return SCREEN_SIZE

async def cancel(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    await update.message.reply_text("ÐžÑ‚Ð¼ÐµÐ½ÐµÐ½Ð¾. ÐÐ°Ð¶Ð¼Ð¸Ñ‚Ðµ /predict Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ð°Ñ‡Ð°Ñ‚ÑŒ Ð·Ð°Ð½Ð¾Ð²Ð¾.")
    return ConversationHandler.END

def main() -> None:
    application = Application.builder().token(TOKEN).build()

    conv_handler = ConversationHandler(
        entry_points=[CommandHandler('predict', predict)],
        states={
            BRAND: [MessageHandler(filters.TEXT & ~filters.COMMAND, get_brand)],
            MODEL: [MessageHandler(filters.TEXT & ~filters.COMMAND, get_model)],
            RAM: [MessageHandler(filters.TEXT & ~filters.COMMAND, get_ram)],
            STORAGE: [MessageHandler(filters.TEXT & ~filters.COMMAND, get_storage)],
            SCREEN_SIZE: [MessageHandler(filters.TEXT & ~filters.COMMAND, get_screen_size)],
        },
        fallbacks=[CommandHandler('cancel', cancel)],
    )

    application.add_handler(CommandHandler('start', start))
    application.add_handler(conv_handler)

    application.run_polling()

if name == 'main':
    main()
